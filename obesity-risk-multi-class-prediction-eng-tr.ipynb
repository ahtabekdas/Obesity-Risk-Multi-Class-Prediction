{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":68479,"databundleVersionId":7609535,"sourceType":"competition"}],"dockerImageVersionId":30646,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Overview / Genel Bakış\n**ENG**\nIn this project, I endeavored to tackle the pressing issue of obesity prediction through a machine learning lens. The aim was to create a robust predictive model that leverages a variety of algorithms to accurately classify individuals' obesity levels based on a series of health-related features. The dataset, sourced from a Kaggle competition, provided a rich foundation for feature engineering, analysis, and model training.\n\n**TR**\nBu projede, obezite tahmini sorununu makine öğrenimi perspektifinden ele almayı amaçladım. Bir dizi sağlıkla ilgili özelliklere dayanarak bireylerin obezite seviyelerini doğru bir şekilde sınıflandırabilen güçlü bir tahmin modeli oluşturmak hedeflendi. Kaggle yarışmasından elde edilen veri seti, özellik mühendisliği, analiz ve model eğitimi için zengin bir temel sundu.\n\n## Data Engineering and Analysis / Veri Mühendisliği ve Analizi\n**ENG**\nThe initial phase involved importing essential libraries and loading the dataset for preprocessing. I performed comprehensive feature engineering to enhance the dataset, which included creating new features such as BMI categories, age groups, and a healthy lifestyle score. Notably, I addressed discrepancies in the test data by aligning categorical values with the training set.\n\n**TR**\nİlk aşama, temel kütüphaneleri içe aktarmak ve veri setini ön işleme için yüklemekle başladı. Veri setini iyileştirmek için kapsamlı özellik mühendisliği gerçekleştirildi; bu, BMI kategorileri, yaş grupları ve sağlıklı yaşam puanı gibi yeni özelliklerin oluşturulmasını içerdi. Test verilerindeki tutarsızlıklar, eğitim setiyle kategorik değerleri hizalayarak giderildi.\n\n## Visualization for Insights / İçgörü için Görselleştirme\n**ENG**\nData visualization played a crucial role in this study, offering a window into the patterns and relationships within the data. Various plots, such as BMI distribution and the impact of active transportation on obesity status, were crafted using libraries like Matplotlib and Seaborn. These visualizations not only provided insights but also guided the feature engineering process.\n\n**TR**\nBu çalışmada veri görselleştirme, veriler içindeki desenleri ve ilişkileri gösteren önemli bir rol oynadı. BMI dağılımı ve aktif ulaşımın obezite durumu üzerindeki etkisi gibi çeşitli grafikler, Matplotlib ve Seaborn kütüphaneleri kullanılarak hazırlandı. Bu görselleştirmeler sadece içgörü sağlamakla kalmadı, aynı zamanda özellik mühendisliği sürecini yönlendirdi.\n\n## Model Development with Optuna Optimization / Optuna Optimizasyonu ile Model Geliştirme\n**ENG**\nI employed Optuna for hyperparameter tuning to determine the optimal settings for several classifiers, including CatBoost, XGBoost, LightGBM, Gradient Boosting, and Random Forest. The models were trained and evaluated individually, with accuracy as the primary metric. I found that the CatBoost and XGBoost models, when combined, yielded the most promising results.\n\n**TR**\nBirçok sınıflandırıcı için optimal ayarları belirlemek amacıyla hiperparametre ayarlaması için Optuna kullandım. Modeller tek tek eğitildi ve değerlendirildi, ana metrik olarak doğruluk kullanıldı. CatBoost ve XGBoost modellerinin birleşimi en umut verici sonuçları verdi.\n\n## Ensemble Learning with Voting Classifier / Oylama Sınıflandırıcısı ile Ansambl Öğrenme\n**ENG**\nSeeking to amplify the predictive power, I utilized a Voting Classifier that harnessed the strengths of the individual models. The soft voting mechanism was applied to combine predictions, leading to a noteworthy improvement in the model's accuracy.\n\n**TR**\nTahmin gücünü artırmak amacıyla, bireysel modellerin güçlerini kullanan bir Oylama Sınıflandırıcısı kullandım. Tahminleri birleştirmek için yumuşak oylama mekanizması uygulandı, bu da modelin doğruluğunda dikkate değer bir iyileşme sağladı.\n\n## Conclusion and Submission / Sonuç ve Gönderim\n**ENG**\nThe final step of this project was to predict obesity levels on the test set using the Voting Classifier I developed. The predictions were carefully formatted and saved into a submission file, which achieved a score of **0.91184** in the Kaggle competition, showcasing the performance of our model.\n\nThis journey through the project has been a testament to the efficacy of ensemble methods in machine learning and their capacity to refine predictions in complex scenarios like obesity prediction. The experience has been an enriching demonstration of the synergy between data science and healthcare, providing valuable insights into the practical application of advanced analytics in real-world health challenges.\n\n**TR**\nBu projenin final adımı, geliştirdiğim Oylama Sınıflandırıcısını kullanarak test setindeki obezite seviyelerini tahmin etmekti. Tahminler özenle biçimlendirildi ve Kaggle yarışmasında **0.91184** puan alarak modelimizin performansını sergileyen bir gönderim dosyasına kaydedildi.\n\nBu proje yolculuğu, obezite tahmini gibi karmaşık senaryolarda tahminleri rafine etme kapasitesi ile makine öğrenimi ensemble yöntemlerinin etkinliğine bir tanıklıktır. Sağlıkla ilgili gerçek dünya zorluğuna uygulanan makine öğreniminin ayrıntılarına dair bu deneyim, veri bilimi ve sağlık bilimleri arasındaki sinerjiyi zengin bir şekilde göstermiş ve ileri analitik uygulamalarının gerçek sağlık sorunlarına nasıl değerli içgörüler sağlayabileceğini ortaya koymuştur.","metadata":{}},{"cell_type":"markdown","source":"# Importing Libraries / Kütüphanelerin İçeri Aktarılması","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport optuna\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.metrics import accuracy_score\n\nfrom sklearn.ensemble import StackingClassifier, RandomForestClassifier, GradientBoostingClassifier\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\nfrom catboost import CatBoostClassifier\n\n\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2024-02-29T16:13:46.487069Z","iopub.execute_input":"2024-02-29T16:13:46.487628Z","iopub.status.idle":"2024-02-29T16:13:46.496870Z","shell.execute_reply.started":"2024-02-29T16:13:46.487588Z","shell.execute_reply":"2024-02-29T16:13:46.495125Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Loading the Data / Verilerin Yüklenmesi","metadata":{}},{"cell_type":"code","source":"data = pd.read_csv(\"/kaggle/input/playground-series-s4e2/train.csv\", index_col=\"id\")\ntest_data = pd.read_csv(\"/kaggle/input/playground-series-s4e2/test.csv\", index_col=\"id\")\nsubmission = pd.read_csv(\"/kaggle/input/playground-series-s4e2/sample_submission.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-02-29T16:13:46.499905Z","iopub.execute_input":"2024-02-29T16:13:46.500584Z","iopub.status.idle":"2024-02-29T16:13:46.662103Z","shell.execute_reply.started":"2024-02-29T16:13:46.500528Z","shell.execute_reply":"2024-02-29T16:13:46.660759Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Feature Engineering / Özellik Mühendisliği\n- **ENG**/ We will create new features with the features we have. **TR**/ Elimizdeki özellikler ile yeni özellikler oluşturacağız.\n- **ENG**/ The \"CALC\" column in the test dataset contains an \"Always\" category that is not present in the training dataset. To address this issue, I will merge the \"Always\" category with the \"Frequently\" category.   **TR**/ Test veri setinde \"CALC\" stünunun içersinde eğitim veri setinin içersinde olmayan \"Always\" kategorisi bulunuyor. Sorunun önüne geçebilmek adına \"Always\" kategorisini \"Frequently\" kategorisine dahil edeceğim. ","metadata":{}},{"cell_type":"code","source":"def new_features(df):\n    \n    \"\"\" BMI (Body Mass Index) Hesaplama ve Kategorilendirme \"\"\"\n    df['BMI'] = df['Weight'] / (df['Height'] ** 2)\n    df['BMI_Category'] = pd.cut(df['BMI'], bins=[0, 18.5, 25, 30, np.inf], labels=[\"Underweight\", \"Normal\", \"Overweight\", \"Obese\"])\n\n    \"\"\" Yaş Kategorileri \"\"\"\n    df['Age_Category'] = pd.cut(df['Age'], bins=[0, 18, 30, 50, np.inf], labels=['Teen', 'Young_Adult', 'Adult', 'Senior'])\n\n    \"\"\" Sağlıklı Yaşam Skoru \"\"\"\n    df['Healthy_Lifestyle_Score'] = (df['FCVC'] + df['NCP'] + df['CH2O'] + df['FAF']) / 4\n\n    \"\"\" Aktif ve Pasif Ulaşım Modları \"\"\"\n    df['Active_Transport'] = df['MTRANS'].apply(lambda x: 1 if x in ['Walking', 'Bike'] else 0)\n    df['Passive_Transport'] = df['MTRANS'].apply(lambda x: 1 if x in ['Automobile', 'Motorbike'] else 0)\n\n    \"\"\" Toplam Su Tüketimi \"\"\"\n    df['Total_Water_Intake'] = df['CH2O'] * df['FAF']\n    \n    return df","metadata":{"execution":{"iopub.status.busy":"2024-02-29T16:13:46.664411Z","iopub.execute_input":"2024-02-29T16:13:46.665152Z","iopub.status.idle":"2024-02-29T16:13:46.676023Z","shell.execute_reply.started":"2024-02-29T16:13:46.665114Z","shell.execute_reply":"2024-02-29T16:13:46.674261Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = new_features(data)\ntest_data = new_features(test_data)","metadata":{"execution":{"iopub.status.busy":"2024-02-29T16:13:46.678004Z","iopub.execute_input":"2024-02-29T16:13:46.678959Z","iopub.status.idle":"2024-02-29T16:13:46.739915Z","shell.execute_reply.started":"2024-02-29T16:13:46.678918Z","shell.execute_reply":"2024-02-29T16:13:46.738908Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data[\"CALC\"].replace({\"Always\": \"Frequently\"}, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-02-29T16:13:46.742483Z","iopub.execute_input":"2024-02-29T16:13:46.743162Z","iopub.status.idle":"2024-02-29T16:13:46.750268Z","shell.execute_reply.started":"2024-02-29T16:13:46.743127Z","shell.execute_reply":"2024-02-29T16:13:46.748892Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Visualization / Veri Görselleştirilmesi","metadata":{}},{"cell_type":"markdown","source":"## Visualizing the Distribution of the Target Variable / Hedef Değişkenin Dağılımını Görselleştirme\n- **ENG**/ We can show the proportion of each class in the dataset by plotting a bar graph that shows the distribution of the target variable. **TR**/ Hedef değişkenin dağılımını gösteren bir bar grafiği çizerek her sınıfın veri setindeki oranını gösterebiliriz.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(10, 6))\nsns.countplot(x='NObeyesdad', data=data)\nplt.title('Distribution of Target Variable / Hedef Değişkenin Dağılımı')\nplt.xticks(rotation=45)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-02-29T16:13:46.752187Z","iopub.execute_input":"2024-02-29T16:13:46.754110Z","iopub.status.idle":"2024-02-29T16:13:47.134529Z","shell.execute_reply.started":"2024-02-29T16:13:46.754024Z","shell.execute_reply":"2024-02-29T16:13:47.133285Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Distribution of BMI Categories / BMI Kategorilerinin Dağılımı\n- **ENG**/ By examining the distribution of BMI categories, we can observe the body mass index status of the participants. **TR**/ BMI kategorilerinin dağılımını inceleyerek, katılımcıların vücut kitle indeksi durumlarını gözlemleyebiliriz.","metadata":{}},{"cell_type":"code","source":"bmi_categories = data[\"BMI_Category\"]\nbmi_counts = bmi_categories.value_counts()\nplt.figure(figsize=(8, 8))\nbmi_counts.plot.pie(autopct='%1.1f%%', startangle=90)\nplt.title('Distribution by BMI Categories')\nplt.ylabel('')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-02-29T16:13:47.136333Z","iopub.execute_input":"2024-02-29T16:13:47.136842Z","iopub.status.idle":"2024-02-29T16:13:47.311695Z","shell.execute_reply.started":"2024-02-29T16:13:47.136809Z","shell.execute_reply":"2024-02-29T16:13:47.310186Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## The Relationship Between Age and BMI / Yaş ve BMI İlişkisi\n- **ENG**/ We can use a scatter plot to examine the relationship between age and BMI. This can show the effect of age on BMI. **TR**/ Yaş ile BMI arasındaki ilişkiyi incelemek için bir scatter plot kullanabiliriz. Bu, yaşın BMI üzerindeki etkisini gösterebiliriz.","metadata":{}},{"cell_type":"code","source":"# Yaş ve BMI İlişkisi\nplt.figure(figsize=(10, 6))\nsns.scatterplot(data=data, x='Age', y='BMI', hue='BMI_Category', style='BMI_Category', palette='viridis')\nplt.title('The Relationship Between Age and BMI / Yaş ve BMI İlişkisi')\nplt.xlabel('Age')\nplt.ylabel('BMI')\nplt.legend(title='BMI Category')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-02-29T16:13:47.313789Z","iopub.execute_input":"2024-02-29T16:13:47.314226Z","iopub.status.idle":"2024-02-29T16:13:48.253315Z","shell.execute_reply.started":"2024-02-29T16:13:47.314191Z","shell.execute_reply":"2024-02-29T16:13:48.251752Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Healthy Life Score Distribution / Sağlıklı Yaşam Skoru Dağılımı\n- **ENG**/ We can plot a histogram to examine the distribution of participants' wellness scores. **TR**/ Katılımcıların sağlıklı yaşam skorlarının dağılımını incelemek için bir histogram çizebiliriz.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(10, 6))\nsns.histplot(data['Healthy_Lifestyle_Score'], kde=True, bins=20)\nplt.title('Healthy Life Score Distribution / Sağlıklı Yaşam Skoru Dağılımı')\nplt.xlabel('Healthy Life Score')\nplt.ylabel('Frequency')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-02-29T16:13:48.255199Z","iopub.execute_input":"2024-02-29T16:13:48.255612Z","iopub.status.idle":"2024-02-29T16:13:48.809765Z","shell.execute_reply.started":"2024-02-29T16:13:48.255581Z","shell.execute_reply":"2024-02-29T16:13:48.808743Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Transportation Modes and Obesity Status / Ulaşım Modları ve Obezite Durumu\n- **ENG**/ We can draw a box plot to show the relationship between transportation modes (active and passive) and obesity status. **TR**/ Ulaşım modları (aktif ve pasif) ile obezite durumu arasındaki ilişkiyi göstermek için bir box plot çizebiliriz.","metadata":{}},{"cell_type":"code","source":"sns.set(style=\"whitegrid\")\n\n# Aktif Ulaşım Modunun Obezite Durumuna Etkisi\nplt.figure(figsize=(12, 8))\nsns.countplot(data=data, x='NObeyesdad', hue='Active_Transport')\nplt.title('Impact of Active Transportation on Obesity Status / 1: Yes 0: No')\nplt.xlabel('Obesity Status')\nplt.ylabel('Number of Individuals')\nplt.xticks(rotation=45)\nplt.legend(title='Active Transportation', loc='upper right')\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-02-29T16:13:48.811432Z","iopub.execute_input":"2024-02-29T16:13:48.812141Z","iopub.status.idle":"2024-02-29T16:13:49.332157Z","shell.execute_reply.started":"2024-02-29T16:13:48.812105Z","shell.execute_reply":"2024-02-29T16:13:49.330186Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Age Distribution Histogram / Yaş Dağılımı Histogramı","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(10, 6))\nsns.histplot(data['Age'], bins=10, kde=True)\nplt.title('Age Distribution Histogram')\nplt.xlabel('Age')\nplt.ylabel('Frequency')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-02-29T16:13:49.338741Z","iopub.execute_input":"2024-02-29T16:13:49.339203Z","iopub.status.idle":"2024-02-29T16:13:49.867094Z","shell.execute_reply.started":"2024-02-29T16:13:49.339167Z","shell.execute_reply":"2024-02-29T16:13:49.865822Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Distribution by Transportation Modes / Ulaşım Türlerine Göre Dağılım","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(10, 6))\nsns.countplot(x='MTRANS', data=data)\nplt.title('Distribution by Transportation Modes')\nplt.ylabel('Number of People')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-02-29T16:13:49.868484Z","iopub.execute_input":"2024-02-29T16:13:49.868860Z","iopub.status.idle":"2024-02-29T16:13:50.191131Z","shell.execute_reply.started":"2024-02-29T16:13:49.868818Z","shell.execute_reply":"2024-02-29T16:13:50.188935Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Label Encoding and Get Dummies\n- **ENG**/ We will convert our target variable to numeric.  **TR**/ Hedef değişkenimizi numerik hale çevireceğiz\n- **ENG**/ We will convert categorical columns with less than 2 data with label encoder, and columns with more than 2 data with get dummies. **TR**/ İçersinde 2'den az veri bulunan kategorik stünları label encoder ile 2 den fazla veri bulunan stünları da get dummies ile dönüştüştüreceğiz.","metadata":{}},{"cell_type":"code","source":"data[\"NObeyesdad\"].replace({\n    \"Insufficient_Weight\": 0,\n    \"Normal_Weight\": 1,\n    \"Overweight_Level_I\": 2,\n    \"Overweight_Level_II\": 3,\n    \"Obesity_Type_I\": 4,\n    \"Obesity_Type_II\": 5,\n    \"Obesity_Type_III\": 6,\n}, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-02-29T16:13:50.193000Z","iopub.execute_input":"2024-02-29T16:13:50.193574Z","iopub.status.idle":"2024-02-29T16:13:50.215030Z","shell.execute_reply.started":"2024-02-29T16:13:50.193539Z","shell.execute_reply":"2024-02-29T16:13:50.213333Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def transform_categorical_values(df):\n    le = LabelEncoder()\n    categorical_columns = df.select_dtypes(include=['object', 'category']).columns.tolist()\n    \n    label_columns = df[categorical_columns].nunique()[df[categorical_columns].nunique() == 2].index.tolist()\n    df[label_columns] = df[label_columns].apply(lambda col: le.fit_transform(col))\n    \n    one_hot_columns = df[categorical_columns].nunique()[df[categorical_columns].nunique() > 2].index.tolist()\n    df = pd.get_dummies(df, columns=one_hot_columns, drop_first=True)\n    \n    return df","metadata":{"execution":{"iopub.status.busy":"2024-02-29T16:13:50.217205Z","iopub.execute_input":"2024-02-29T16:13:50.217677Z","iopub.status.idle":"2024-02-29T16:13:50.225888Z","shell.execute_reply.started":"2024-02-29T16:13:50.217641Z","shell.execute_reply":"2024-02-29T16:13:50.224486Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = transform_categorical_values(data)\ntest_data = transform_categorical_values(test_data)","metadata":{"execution":{"iopub.status.busy":"2024-02-29T16:13:50.228206Z","iopub.execute_input":"2024-02-29T16:13:50.229623Z","iopub.status.idle":"2024-02-29T16:13:50.427241Z","shell.execute_reply.started":"2024-02-29T16:13:50.229564Z","shell.execute_reply":"2024-02-29T16:13:50.425224Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Eğitim ve Test Seti Oluşturma\n- **ENG**/ I will exclude the target variable data from the data dataset and assign the training data to x, then I will only assign the dependent variable to y only. **TR**/ Hedef değişkeni data veri seti dışında tutup eğitim verilerini x'e atayacağım ardından sadece bağımlı değişkeni sadece y'ye atayacağım.\n- **ENG**/ With Train Test Split, I will determine test_size and random_state and separate the training and test sets. **TR**/ Train Test Split ile test_size ve random_state'i belirleyip eğitim ve test setlerini ayıracağım.","metadata":{}},{"cell_type":"code","source":"x = data.drop(\"NObeyesdad\", axis=1)\ny = data[\"NObeyesdad\"]","metadata":{"execution":{"iopub.status.busy":"2024-02-29T16:14:20.606273Z","iopub.execute_input":"2024-02-29T16:14:20.607351Z","iopub.status.idle":"2024-02-29T16:14:20.615651Z","shell.execute_reply.started":"2024-02-29T16:14:20.607312Z","shell.execute_reply":"2024-02-29T16:14:20.613660Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=42)\n\n# Checking the size of data / Verilerin boyutlarını kontrol etme\nprint(f\"Train Data Shape: {x_train.shape}\")\nprint(f\"Test Data Shape: {x_test.shape}\")","metadata":{"execution":{"iopub.status.busy":"2024-02-29T16:14:20.764520Z","iopub.execute_input":"2024-02-29T16:14:20.765233Z","iopub.status.idle":"2024-02-29T16:14:20.784103Z","shell.execute_reply.started":"2024-02-29T16:14:20.765185Z","shell.execute_reply":"2024-02-29T16:14:20.782824Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# OPTUNA\n- **ENG**/ I will try to find the most suitable parameters for CATBOOST, XGBOOST, LIGHTGBM, GRADIENTBOOSTING, RANDOMFOREST models with Optuna. **TR**/ Optuna ile CATBOOST, XGBOOST, LIGHTGBM, GRADIENTBOOSTING, RANDOMFOREST modelleri için en uygun parametreleri bulmaya çalışacağım.","metadata":{}},{"cell_type":"markdown","source":"## 1. CatBoostClassifier","metadata":{}},{"cell_type":"code","source":"#def objective(trial):\n#    # Hiperparametre aralıklarını tanımlama\n#    param = {\n#        'iterations': trial.suggest_int('iterations', 100, 2000),\n#        'depth': trial.suggest_int('depth', 2, 10),\n#        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n#        'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 0.01, 10),\n#        'border_count': trial.suggest_int('border_count', 32, 255),\n#        'bagging_temperature': trial.suggest_float('bagging_temperature', 0.0, 1.0),\n#        'random_strength': trial.suggest_float('random_strength', 0.001, 1.0),\n#        'grow_policy': trial.suggest_categorical('grow_policy', ['SymmetricTree', 'Depthwise', 'Lossguide']),\n#        'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 1, 20)\n#    }\n#\n#    # 'max_leaves' sadece 'Lossguide' grow_policy için geçerli\n#    if param['grow_policy'] == 'Lossguide':\n#        param['max_leaves'] = trial.suggest_int('max_leaves', 31, 64)\n#\n#    # CatBoostClassifier modelini oluşturma ve eğitme\n#    model = CatBoostClassifier(**param, verbose=0, early_stopping_rounds=100)\n#    model.fit(x_train, y_train, eval_set=[(x_test, y_test)], verbose=0)\n#\n#    # Modelin doğruluğunu hesaplama\n#    preds = model.predict(x_test)\n#    accuracy = accuracy_score(y_test, preds)\n#    return accuracy\n#\n## Optuna study nesnesi oluşturma ve optimizasyon başlatma\n#study = optuna.create_study(direction='maximize')\n#study.optimize(objective, n_trials=2005)","metadata":{"execution":{"iopub.status.busy":"2024-02-29T16:14:21.224548Z","iopub.execute_input":"2024-02-29T16:14:21.225610Z","iopub.status.idle":"2024-02-29T16:14:21.232836Z","shell.execute_reply.started":"2024-02-29T16:14:21.225548Z","shell.execute_reply":"2024-02-29T16:14:21.230914Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### **ENG**/ I have reached the following results after parameter search with Optuna for CatBoost: **TR**/ Optuna ile CatBoost parametre aramasının sonucunda şunlara eriştim:\n- [I 2024-02-22 05:48:58,400] *Trial 871 finished with value:* **0.9135356454720617** *and parameters:* {'iterations': 1355, 'depth': 5, 'learning_rate': 0.1096384174794031, 'l2_leaf_reg': 5.010224281972051, 'border_count': 240, 'bagging_temperature': 0.10565271312223717, 'random_strength': 0.3295302174116903, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 16}. **Best is trial 871 with value: 0.9135356454720617.**","metadata":{}},{"cell_type":"markdown","source":"## 2. XGBClassifier","metadata":{}},{"cell_type":"code","source":"#def objective_xgboost(trial):\n#    # Hiperparametre aralıklarını tanımlama\n#    param = {\n#        'n_estimators': trial.suggest_int('n_estimators', 100, 2000),\n#        'max_depth': trial.suggest_int('max_depth', 3, 20),\n#        'learning_rate': trial.suggest_float('learning_rate', 0.01, 1.0),\n#        'subsample': trial.suggest_float('subsample', 0.20, 1.0),\n#        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.20, 1.0),\n#        'gamma': trial.suggest_float('gamma', 1e-10, 1.0),\n#        'reg_alpha': trial.suggest_float('reg_alpha', 1e-5, 5),\n#        'reg_lambda': trial.suggest_float('reg_lambda', 1e-5, 5),\n#        'min_child_weight': trial.suggest_int('min_child_weight', 1, 30),\n#        \n#\n#    }\n#\n#    # XGBoost modelini oluşturma ve eğitme\n#    model = XGBClassifier(**param, early_stopping_rounds=200, random_state=42)\n#    model.fit(x_train, y_train, eval_set=[(x_test, y_test)], verbose=0)\n#\n#    # Modelin doğruluğunu hesaplama\n#    preds = model.predict(x_test)\n#    accuracy = accuracy_score(y_test, preds)\n#    return accuracy\n#\n## Optuna study nesnesi oluşturma ve optimizasyon başlatma\n#study_xgboost = optuna.create_study(direction='maximize')\n#study_xgboost.optimize(objective_xgboost, n_trials=2005)","metadata":{"execution":{"iopub.status.busy":"2024-02-29T16:14:21.683350Z","iopub.execute_input":"2024-02-29T16:14:21.684017Z","iopub.status.idle":"2024-02-29T16:14:21.689664Z","shell.execute_reply.started":"2024-02-29T16:14:21.683983Z","shell.execute_reply":"2024-02-29T16:14:21.687868Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### **ENG**/ I have reached the following results after parameter search with Optuna for XGBoost: **TR**/ Optuna ile XGBoost parametre aramasının sonucunda şunlara eriştim:\n- [I 2024-02-22 14:27:03,497] *Trial 1033 finished with value:* **0.914980732177264** *and parameters:* {'n_estimators': 1653, 'max_depth': 3, 'learning_rate': 0.08346083239445595, 'subsample': 0.9473612065571799, 'colsample_bytree': 0.2727334724076542, 'gamma': 0.035093546773850515, 'reg_alpha': 2.0084596983174867, 'reg_lambda': 4.700706962671846, 'min_child_weight': 1}. **Best is trial 1033 with value: 0.914980732177264.**","metadata":{}},{"cell_type":"markdown","source":"## 3. LGBMClassifier","metadata":{}},{"cell_type":"code","source":"#def objective_lightgbm(trial):\n#    param = {\n#        'objective': 'multiclass',\n#        'metric': 'multi_logloss',\n#        'num_class': len(set(y_train)),  # Sınıf sayısını belirtin\n#        'verbosity': -1,\n#        'boosting_type': 'gbdt',\n#        'lambda_l1': trial.suggest_float('lambda_l1', 1e-10, 20.0, log=True),\n#        'lambda_l2': trial.suggest_float('lambda_l2', 1e-10, 20.0, log=True),\n#        'num_leaves': trial.suggest_int('num_leaves', 2, 512),\n#        'feature_fraction': trial.suggest_float('feature_fraction', 0.4, 1.0),\n#        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.4, 1.0),\n#        'bagging_freq': trial.suggest_int('bagging_freq', 0.001, 10),\n#        'min_child_samples': trial.suggest_int('min_child_samples', 1, 100),\n#        'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.3),\n#        'max_depth': trial.suggest_int('max_depth', -1, 100),  # -1 means no limit\n#        'min_gain_to_split': trial.suggest_float('min_gain_to_split', 0, 50),\n#        'min_child_weight': trial.suggest_float('min_child_weight', 1e-7, 1e-5, log=True),\n#        'min_sum_hessian_in_leaf': trial.suggest_float('min_sum_hessian_in_leaf', 1e-8, 1e-5, log=True)\n#    }\n#\n#    # Create and train LightGBM model\n#    model = LGBMClassifier(**param, early_stopping_rounds=100, random_state=42, verbose=0)\n#    model.fit(x_train, y_train, eval_set=[(x_test, y_test)])\n#\n#    # Evaluate model performance\n#    preds = model.predict(x_test)\n#    accuracy = accuracy_score(y_test, preds)\n#    return accuracy\n#\n## Optuna study nesnesi oluşturma ve optimizasyon başlatma\n#study_lightgbm = optuna.create_study(direction='maximize')\n#study_lightgbm.optimize(objective_lightgbm, n_trials=4000)","metadata":{"execution":{"iopub.status.busy":"2024-02-29T16:14:22.096781Z","iopub.execute_input":"2024-02-29T16:14:22.097247Z","iopub.status.idle":"2024-02-29T16:14:22.105067Z","shell.execute_reply.started":"2024-02-29T16:14:22.097215Z","shell.execute_reply":"2024-02-29T16:14:22.103708Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### **ENG**/ I have reached the following results after parameter search with Optuna for LGBMClassifier: **TR**/ Optuna ile LGBMClassifier parametre aramasının sonucunda şunlara eriştim:\n- [I 2024-02-22 13:37:47,196] *Trial 3253 finished with value:* **0.9123314065510597** *and parameters:* {'lambda_l1': 0.0034407365453225976, 'lambda_l2': 0.14618731005541508, 'num_leaves': 19, 'feature_fraction': 0.40031517145679507, 'bagging_fraction': 0.6394939715840073, 'bagging_freq': 10, 'min_child_samples': 1, 'learning_rate': 0.10868460654536086, 'max_depth': 88, 'min_gain_to_split': 0.015546065137711812, 'min_child_weight': 2.6133446037573905e-07, 'min_sum_hessian_in_leaf': 6.347168996577988e-06}. **Best is trial 3253 with value: 0.9123314065510597.**","metadata":{}},{"cell_type":"markdown","source":"## 4. GradientBoostingClassifier","metadata":{}},{"cell_type":"code","source":"#def objective_gradient_boosting(trial):\n#    param = {\n#        'n_estimators': trial.suggest_int('n_estimators', 100, 2000),\n#        'max_depth': trial.suggest_int('max_depth', 3, 15),\n#        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.5, log=True),\n#        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n#        'min_samples_split': trial.suggest_int('min_samples_split', 2, 100),\n#        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 50),\n#        'max_features': trial.suggest_categorical('max_features', ['sqrt', 'log2']),\n#        'validation_fraction': trial.suggest_float('validation_fraction', 0.1, 0.3),\n#        'n_iter_no_change': trial.suggest_int('n_iter_no_change', 5, 20),\n#        'tol': trial.suggest_float('tol', 1e-5, 1e-3, log=True),\n#        'random_state': 42\n#    }\n#\n#    # GradientBoostingClassifier modelini oluşturma ve eğitme\n#    model = GradientBoostingClassifier(**param)\n#    model.fit(x_train, y_train)\n#\n#    # Modelin doğruluğunu hesaplama\n#    preds = model.predict(x_test)\n#    accuracy = accuracy_score(y_test, preds)\n#    return accuracy\n#\n## Optuna study nesnesi oluşturma ve optimizasyon başlatma\n#study_gradient_boosting = optuna.create_study(direction='maximize')\n#study_gradient_boosting.optimize(objective_gradient_boosting, n_trials=2005)","metadata":{"execution":{"iopub.status.busy":"2024-02-29T16:14:23.068526Z","iopub.execute_input":"2024-02-29T16:14:23.069133Z","iopub.status.idle":"2024-02-29T16:14:23.077592Z","shell.execute_reply.started":"2024-02-29T16:14:23.069097Z","shell.execute_reply":"2024-02-29T16:14:23.075092Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### **ENG**/ I have reached the following results after parameter search with Optuna for GradientBoostingClassifier: **TR**/ Optuna ile GradientBoostingClassifier parametre aramasının sonucunda şunlara eriştim:\n- [I 2024-02-22 04:21:59,956] *Trial 220 finished with value:* **0.9104046242774566** *and parameters:* {'n_estimators': 653, 'max_depth': 7, 'learning_rate': 0.01630624786154065, 'subsample': 0.9267674351619599, 'min_samples_split': 83, 'min_samples_leaf': 10, 'max_features': 'sqrt', 'validation_fraction': 0.15505642008587056, 'n_iter_no_change': 7, 'tol': 1.1030772570725336e-05}. **Best is trial 220 with value: 0.9104046242774566.**","metadata":{}},{"cell_type":"markdown","source":"## 5. RandomForestClassifier","metadata":{}},{"cell_type":"code","source":"#from sklearn.ensemble import RandomForestClassifier\n#\n#def objective_random_forest(trial):\n#    param = {\n#        'n_estimators': trial.suggest_int('n_estimators', 100, 2000),\n#        'max_depth': trial.suggest_int('max_depth', 5, 100),\n#        'min_samples_split': trial.suggest_int('min_samples_split', 2, 50),\n#        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 20),\n#        'bootstrap': trial.suggest_categorical('bootstrap', [True, False]),\n#        'class_weight': trial.suggest_categorical('class_weight', ['balanced', 'balanced_subsample', None]),\n#        'random_state': 42\n#    }\n#\n#    # RandomForest modelini oluşturma ve eğitme\n#    model = RandomForestClassifier(**param)\n#    model.fit(x_train, y_train)\n#\n#    # Modelin doğruluğunu hesaplama\n#    preds = model.predict(x_test)\n#    accuracy = accuracy_score(y_test, preds)\n#    return accuracy\n#\n## Optuna study nesnesi oluşturma ve optimizasyon başlatma\n#study_random_forest = optuna.create_study(direction='maximize')\n#study_random_forest.optimize(objective_random_forest, n_trials=1000)","metadata":{"execution":{"iopub.status.busy":"2024-02-29T16:14:23.588220Z","iopub.execute_input":"2024-02-29T16:14:23.588786Z","iopub.status.idle":"2024-02-29T16:14:23.596542Z","shell.execute_reply.started":"2024-02-29T16:14:23.588744Z","shell.execute_reply":"2024-02-29T16:14:23.594528Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### **ENG**/ I have reached the following results after parameter search with Optuna for RandomForestClassifier: **TR**/ Optuna ile RandomForestClassifier parametre aramasının sonucunda şunlara eriştim:\n\n- [I 2024-02-22 08:38:06,226] *Trial 468 finished with value:* **0.901252408477842** *and parameters:* {'n_estimators': 1596, 'max_depth': 92, 'min_samples_split': 12, 'min_samples_leaf': 1, 'bootstrap': False, 'class_weight': 'balanced'}. **Best is trial 468 with value: 0.901252408477842.**","metadata":{}},{"cell_type":"markdown","source":"## Creating models with the best parameters I found / Bulduğum en iyi parametreler ile modelleri oluşturma","metadata":{}},{"cell_type":"code","source":"catboost_model = CatBoostClassifier(\n    iterations=1819, depth=5, learning_rate=0.1014969073551741, l2_leaf_reg=5.34593664307217, \n    border_count=164, bagging_temperature=0.8408771489965642, random_strength=0.7008891194758375, grow_policy='Depthwise',\n    min_data_in_leaf=16, verbose=0)\n\nxgboost_model = XGBClassifier(\n    n_estimators=1653, max_depth=3, learning_rate=0.08346083239445595, subsample=0.9473612065571799, \n    colsample_bytree=0.2727334724076542, gamma=0.035093546773850515, reg_alpha=2.0084596983174867, \n    reg_lambda=4.700706962671846, min_child_weight= 1, verbosity=0)\n\nlightgbm_model = LGBMClassifier(\n    lambda_l1=0.0034407365453225976, lambda_l2=0.14618731005541508, num_leaves=19, \n    feature_fraction=0.40031517145679507, bagging_fraction=0.6394939715840073, bagging_freq=10, \n    min_child_samples=1, learning_rate=0.10868460654536086, max_depth=88, min_gain_to_split=0.015546065137711812, \n    min_child_weight=2.6133446037573905e-07, min_sum_hessian_in_leaf=6.347168996577988e-06, verbose=-1)\n\ngradient_boosting_model = GradientBoostingClassifier(\n    n_estimators=653, max_depth=7, learning_rate=0.01630624786154065, subsample=0.9267674351619599, \n    min_samples_split=83, min_samples_leaf=10, max_features='sqrt',validation_fraction=0.15505642008587056, n_iter_no_change=7,\n    tol=1.1030772570725336e-05)\n\nrandom_forest_model = RandomForestClassifier(\n    n_estimators=930, max_depth=326, min_samples_split=7, min_samples_leaf=1, bootstrap=True, class_weight=None\n)","metadata":{"execution":{"iopub.status.busy":"2024-02-29T16:14:24.090767Z","iopub.execute_input":"2024-02-29T16:14:24.091619Z","iopub.status.idle":"2024-02-29T16:14:24.106527Z","shell.execute_reply.started":"2024-02-29T16:14:24.091582Z","shell.execute_reply":"2024-02-29T16:14:24.104803Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Evaluating the Models We Created One by One / Oluşturduğumuz Modelleri Tek Tek Değerlendirme","metadata":{}},{"cell_type":"code","source":"def train_and_evaluate(model, x_train, y_train, x_test, y_test):\n    model.fit(x_train, y_train)\n    preds = model.predict(x_test)\n    accuracy = accuracy_score(y_test, preds)\n    return accuracy\n\nmodels = [\n    ('CatBoost', catboost_model),\n    ('XGBoost', xgboost_model),\n    ('LightGBM', lightgbm_model),\n    ('Gradient Boosting', gradient_boosting_model),\n    ('Random Forest',random_forest_model)\n]\n\nfor name, model in models:\n    accuracy = train_and_evaluate(model, x_train, y_train, x_test, y_test)\n    print(f\"{name} Model Accuracy: {accuracy:.4f}\")","metadata":{"execution":{"iopub.status.busy":"2024-02-29T16:14:24.385961Z","iopub.execute_input":"2024-02-29T16:14:24.386380Z","iopub.status.idle":"2024-02-29T16:17:10.661879Z","shell.execute_reply.started":"2024-02-29T16:14:24.386349Z","shell.execute_reply":"2024-02-29T16:17:10.660580Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Voting Classifier / Oylama Sınıflandırıcısı\n- **ENG**/ I will try to increase the score further by combining the power of the models we have created using a Voting Classifier. **TR**/ Oluşturduğumuz modellerin gücünü Voting Classifier ile birleştirerek skoru daha da arttırmaya çalışacağım.","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import VotingClassifier\n\nvoting_clf = VotingClassifier(\n    estimators=[\n        ('catboost', catboost_model),\n        ('xgboost', xgboost_model),\n        #('lightgbm', lightgbm_model),\n        #('random_forest', random_forest_model),\n        #('gradient_boosting', gradient_boosting_model)\n    ],\n    voting='soft'\n)\n\nvoting_clf.fit(x_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2024-02-29T16:17:10.664395Z","iopub.execute_input":"2024-02-29T16:17:10.665267Z","iopub.status.idle":"2024-02-29T16:18:52.170689Z","shell.execute_reply.started":"2024-02-29T16:17:10.665223Z","shell.execute_reply":"2024-02-29T16:18:52.169421Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#catboost+xgboost+lightgbm+gradient_boosting                SOFT = 0.9097\n#catboost+xgboost+lightgbm+gradient_boosting+randomforest   SOFT = 0.9092\n#catboost+xgboost+lightgbm+randomforest                     SOFT = 0.9094\n#catboost+xgboost+lightgbm                                  SOFT = 0.9111\n#catboost+xgboost                                           SOFT = 0.9135\n#catboost                                                   SOFT = 0.9116\n#catboost+lightgbm                                          SOFT = 0.9109\n#xgboost+lightgbm                                           SOFT = 0.9098\n#xgboost                                                    SOFT = 0.9104\n#catboost+xgboost+gradient_boosting                         SOFT = 0.9094\n#catboost+xgboost+randomforest                              SOFT = 0.9106\n#catboost+randomforest                                      SOFT = 0.9109\n#catboost+lightgbm+randomforest                             SOFT = 0.9075\n\naccuracy = voting_clf.score(x_test, y_test) \nprint(f\"Voting Ensemble Model Accuracy: {accuracy:.4f}\")","metadata":{"execution":{"iopub.status.busy":"2024-02-29T16:18:52.171996Z","iopub.execute_input":"2024-02-29T16:18:52.172327Z","iopub.status.idle":"2024-02-29T16:18:52.934158Z","shell.execute_reply.started":"2024-02-29T16:18:52.172300Z","shell.execute_reply":"2024-02-29T16:18:52.932939Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### - **ENG**/ I got the highest score with the combination of catboost and xgboost. **TR**/ En yüksek skoru catboost ve xgboost kombinasyonu ile aldım.","metadata":{}},{"cell_type":"markdown","source":"# Preparation of the Submission File\n- **ENG**/ I'm gonna predict the test data set with the voting_clf model I created. **TR**/ Test veri setini oluşturduğum voting_clf modeli ile tahmin edeceğim.\n- **ENG**/ I'm gonna convert the predicted column to the desired format. **TR**/ Tahmin edilen sütunu istenen formata dönüştüreceğim.\n- **ENG**/ I will save the submission file. **TR**/ Submission dosyasını kaydedeceğim. ","metadata":{}},{"cell_type":"code","source":"final_preds = voting_clf.predict(test_data)","metadata":{"execution":{"iopub.status.busy":"2024-02-29T16:18:52.936332Z","iopub.execute_input":"2024-02-29T16:18:52.936678Z","iopub.status.idle":"2024-02-29T16:18:55.413868Z","shell.execute_reply.started":"2024-02-29T16:18:52.936650Z","shell.execute_reply":"2024-02-29T16:18:55.412614Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission[\"NObeyesdad\"] = final_preds","metadata":{"execution":{"iopub.status.busy":"2024-02-29T16:18:55.417750Z","iopub.execute_input":"2024-02-29T16:18:55.418151Z","iopub.status.idle":"2024-02-29T16:18:55.422910Z","shell.execute_reply.started":"2024-02-29T16:18:55.418121Z","shell.execute_reply":"2024-02-29T16:18:55.422005Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission[\"NObeyesdad\"] = submission[\"NObeyesdad\"].replace({\n    0: \"Insufficient_Weight\",\n    1: \"Normal_Weight\",\n    2: \"Overweight_Level_I\",\n    3: \"Overweight_Level_II\",\n    4: \"Obesity_Type_I\",\n    5: \"Obesity_Type_II\",\n    6: \"Obesity_Type_III\"\n})","metadata":{"execution":{"iopub.status.busy":"2024-02-29T16:18:55.424068Z","iopub.execute_input":"2024-02-29T16:18:55.424910Z","iopub.status.idle":"2024-02-29T16:18:55.440189Z","shell.execute_reply.started":"2024-02-29T16:18:55.424876Z","shell.execute_reply":"2024-02-29T16:18:55.439269Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-02-29T16:18:55.441285Z","iopub.execute_input":"2024-02-29T16:18:55.441844Z","iopub.status.idle":"2024-02-29T16:18:55.468005Z","shell.execute_reply.started":"2024-02-29T16:18:55.441814Z","shell.execute_reply":"2024-02-29T16:18:55.466884Z"},"trusted":true},"execution_count":null,"outputs":[]}]}